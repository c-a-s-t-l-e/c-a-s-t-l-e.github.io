# An Overview of Tabnet - Tabular Data Deep Learning

Hey guys! I've been exploring the tabnet model for a few days since stumbling upon it in a Github repo. For the sake of the this post, I would just like put down my understanding of the model to help you and I better understand it.

First and foremost, I would like to credit Francesco Pochetti for the images and symbolic dictionary from [his blog post](https://francescopochetti.com/tabular-deep-leaning-tabnet-deep-dive/) on Tabnet. I would also like to put in the direction of [the paper](https://arxiv.org/pdf/1908.07442) and [Dreamquark's Github repo](https://github.com/dreamquark-ai/tabnet) that has the model implemented in Pytorch. 

With that being said, we could probably start with an initial overview of the model with the image below:

![](http://c-a-s-t-l-e.github.io/images/tabnet/all_together.png)

---

To understand what we're looking out, we can reference the dictionary provided:

![](http://c-a-s-t-l-e.github.io/images/tabnet/symbol_dictionary.png)

As well as noting that:

**BS** -> batch size

**input** -> shape of the input dataset, e.g. number of features passed to the model.

**n_d** -> size of the decision layer, e.g. input features are mapped to n_d (where n_d<input) in Fully Connected (FC) layers.

**n_a** -> size of the attention bottleneck, e.g. input features are mapped to n_a (where n_a<input) and then to input again, giving the model a chance to learn which attributes to focus on.

---

Now, we could focus on the first part of the model:

![](http://c-a-s-t-l-e.github.io/images/tabnet/first_select_together.png)
