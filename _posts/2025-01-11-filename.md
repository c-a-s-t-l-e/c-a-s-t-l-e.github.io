# An Overview of Tabnet - Tabular Data Deep Learning

Hey guys! I've been exploring the tabnet model for a few days since stumbling upon it in a Github repo. For the sake of the this post, I would just like put down my understanding of the model to help you and I better understand it.

First and foremost, I would like to credit Francesco Pochetti for the images and symbolic dictionary from [his blog post](https://francescopochetti.com/tabular-deep-leaning-tabnet-deep-dive/) on Tabnet. I would also like to put in the direction of [the paper](https://arxiv.org/pdf/1908.07442) and [Dreamquark's Github repo](https://github.com/dreamquark-ai/tabnet) that has the model implemented in Pytorch. 

With that being said, we could probably start with an initial overview of the model with the image below:

![](http://c-a-s-t-l-e.github.io/images/tabnet/all_together.png)

---

To understand what we're looking out, we can reference the dictionary provided:

![](http://c-a-s-t-l-e.github.io/images/tabnet/symbol_dictionary.png)

As well as noting that:

**BS** -> batch size

**input** -> shape of the input dataset, e.g. number of features passed to the model.

**n_d** -> size of the decision layer, e.g. input features are mapped to n_d (where n_d<input) in Fully Connected (FC) layers.

**n_a** -> size of the attention bottleneck, e.g. input features are mapped to n_a (where n_a<input) and then to input again, giving the model a chance to learn which attributes to focus on.

---

Now, we could focus on the first part of the model:

![](http://c-a-s-t-l-e.github.io/images/tabnet/first_select_together.png)

---

## BN - Batch Normalization

The first part to notice is that we have the input that leads to "BN" or the batch normalization component.

Batch normalization can be understood through this mathematical pseudo-code:

```python
    def batch_norm_math(self, X):
        # For batch B of size m
        μᵢ = (1/m)Σₘ xᵢᵐ            # Mean per feature
        σ²ᵢ = (1/m)Σₘ(xᵢᵐ - μᵢ)²    # Variance per feature
        x̂ᵢ = (xᵢ - μᵢ)/√(σ²ᵢ + ε)   # Normalized features
        
        return x̂ᵢ
```

Essentially, you could think of manipulating the data to mitigate extremes among other characteristics in the input dataset.

Also, the reason why we use the word "batch" is because a batch of data is sent to the model as input.

---

## Feature Trans - Feature Transformer

After the normalized data is created, it gets fed into the feature transformer which can be understood through the following image:

![](http://c-a-s-t-l-e.github.io/images/tabnet/feature_transformer.png)

